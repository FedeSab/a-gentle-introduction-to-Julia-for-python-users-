{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First than all, you can download Julia from https://julialang.org/downloads/ \n",
    "\n",
    "I'm using Julia 1.8.2 (last version to date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For allowing Julia code to be run in notebooks:\n",
    "- After downloading Julia, open console and run:\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg; Pkg.add(\"IJulia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pkg is Julia's builtin package manager**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Activating an enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Julia you can activate enviroments by using (in console):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg; Pkg.activate(\"PATH_TO_FOLDER\"); Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace \"PATH_TO_FOLDER\" with your path to the folder where you have a Project.toml file.\n",
    "\n",
    "If already in folder, put a \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages I'm using:\n",
    "\n",
    "  \"CSV\"            => v\"0.10.7\"\n",
    "\n",
    "\n",
    "  \"MLJ\"            => v\"0.19.0\"\n",
    "\n",
    "\n",
    "  \"BenchmarkTools\" => v\"1.3.2\"\n",
    "\n",
    "\n",
    "  \"Missings\"       => v\"1.0.2\"\n",
    "\n",
    "\n",
    "  \"ScikitLearn\"    => v\"0.6.5\"\n",
    "\n",
    "\n",
    "  \"StatsBase\"      => v\"0.33.21\"\n",
    "\n",
    "\n",
    "  \"IJulia\"         => v\"1.23.3\"\n",
    "\n",
    "\n",
    "  \"LightGBM\"       => v\"0.6.0\"\n",
    "\n",
    "\n",
    "  \"MLJModels\"      => v\"0.16.0\"\n",
    "\n",
    "\n",
    "  \"DataFrames\"     => v\"1.4.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentations <a id=\"docs\"></a>\n",
    "\n",
    "Here are some links that help my out.\n",
    "\n",
    "- [Official Documentation](https://docs.julialang.org/en/v1/)\n",
    "- [DataFrames](https://dataframes.juliadata.org/stable/man/comparisons/#Comparison-with-the-Python-package-pandas) Julia's package to work with dataframes. It even has a comparison with pandas.\n",
    "- [Scikitlearn.jl](https://juliapackages.com/p/scikitlearn) Probably you don't want to use it. More on that later.\n",
    "-  [Stadistics](https://docs.julialang.org/en/v1/stdlib/Statistics/) standard library and [BaseStats](https://juliastats.org/StatsBase.jl/stable/) a package that provides basic support for statistics.\n",
    "-  [MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/) (Machine Learning Framework for Julia) It has a lot of examples and a good structured documentation. [More examples](https://juliaai.github.io/DataScienceTutorials.jl/end-to-end/boston-lgbm/)\n",
    "-  [Performance tips](https://docs.julialang.org/en/v1/manual/performance-tips/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll probably understand Julia well enough if you already know a lot about Python. \n",
    "The sad part of Julia to this date, for me at least, is that I'm more used to Python and in Python you don't only have a great documentation, you have a HUGE community with millions of users and tutorials everywhere on the internet. Don't get me wrong, Julias has a lot of users, but the documentation could be better also while doing this project I run into some compatibility issues between libraries. So, I think that if Julia starts getting more attention could shine and show its full capabilities for ML.\n",
    "\n",
    "Next, I want to show to interesting things: The \"! method\" and about using sklearn on Julia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"! method\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Julia functions/methods have a ! \"version\", for example replace and replace!. The first one returns a copy of the object and the latter change memory inplace. Why is this important? Well... ! funtions are faster. Consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>6000001×1 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">5999976 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">x1</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Union{Missing, Float64}\" style = \"text-align: left;\">Float64?</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">4.26358e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">414927.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">3.96343e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">3.25033e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"font-style: italic; text-align: right;\">missing</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">1.865e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">300258.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">4.89609e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">909949.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">4.473e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">2.16893e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">2.30699e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">431220.0</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999990</td><td style = \"text-align: right;\">30221.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999991</td><td style = \"text-align: right;\">1.65932e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999992</td><td style = \"font-style: italic; text-align: right;\">336299.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999993</td><td style = \"text-align: right;\">4.86734e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999994</td><td style = \"text-align: right;\">missing</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999995</td><td style = \"text-align: right;\">missing</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999996</td><td style = \"text-align: right;\">2.54829e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999997</td><td style = \"text-align: right;\">2.70461e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999998</td><td style = \"text-align: right;\">9804.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5999999</td><td style = \"text-align: right;\">1.63036e6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6000000</td><td style = \"text-align: right;\">missing</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6000001</td><td style = \"text-align: right;\">4.86655e6</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& x1\\\\\n",
       "\t\\hline\n",
       "\t& Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & 4.26358e6 \\\\\n",
       "\t2 & 414927.0 \\\\\n",
       "\t3 & 3.96343e6 \\\\\n",
       "\t4 & 3.25033e6 \\\\\n",
       "\t5 & \\emph{missing} \\\\\n",
       "\t6 & 1.865e6 \\\\\n",
       "\t7 & 300258.0 \\\\\n",
       "\t8 & 4.89609e6 \\\\\n",
       "\t9 & 909949.0 \\\\\n",
       "\t10 & 4.473e6 \\\\\n",
       "\t11 & 2.16893e6 \\\\\n",
       "\t12 & 2.30699e6 \\\\\n",
       "\t13 & 431220.0 \\\\\n",
       "\t14 & 3.35365e6 \\\\\n",
       "\t15 & 395631.0 \\\\\n",
       "\t16 & \\emph{missing} \\\\\n",
       "\t17 & 191513.0 \\\\\n",
       "\t18 & 3.38726e6 \\\\\n",
       "\t19 & 417856.0 \\\\\n",
       "\t20 & 1.33325e6 \\\\\n",
       "\t21 & 3.75524e6 \\\\\n",
       "\t22 & 2.6159e6 \\\\\n",
       "\t23 & 652632.0 \\\\\n",
       "\t24 & 4.85393e6 \\\\\n",
       "\t25 & 4.0445e6 \\\\\n",
       "\t26 & 4.57522e6 \\\\\n",
       "\t27 & 2.73758e6 \\\\\n",
       "\t28 & 1.33556e6 \\\\\n",
       "\t29 & 849788.0 \\\\\n",
       "\t30 & 278273.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6000001×1 DataFrame\u001b[0m\n",
       "\u001b[1m     Row \u001b[0m│\u001b[1m x1              \u001b[0m\n",
       "         │\u001b[90m Float64?        \u001b[0m\n",
       "─────────┼─────────────────\n",
       "       1 │       4.26358e6\n",
       "       2 │  414927.0\n",
       "       3 │       3.96343e6\n",
       "       4 │       3.25033e6\n",
       "       5 │\u001b[90m missing         \u001b[0m\n",
       "       6 │       1.865e6\n",
       "       7 │  300258.0\n",
       "       8 │       4.89609e6\n",
       "       9 │  909949.0\n",
       "      10 │       4.473e6\n",
       "      11 │       2.16893e6\n",
       "    ⋮    │        ⋮\n",
       " 5999992 │  336299.0\n",
       " 5999993 │       4.86734e6\n",
       " 5999994 │\u001b[90m missing         \u001b[0m\n",
       " 5999995 │\u001b[90m missing         \u001b[0m\n",
       " 5999996 │       2.54829e6\n",
       " 5999997 │       2.70461e6\n",
       " 5999998 │    9804.0\n",
       " 5999999 │       1.63036e6\n",
       " 6000000 │\u001b[90m missing         \u001b[0m\n",
       " 6000001 │       4.86655e6\n",
       "\u001b[36m       5999980 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "using BenchmarkTools\n",
    "using Random \n",
    "\n",
    "a = collect(1:5000000) #Creating a INT array of 5.000.000 numbers\n",
    "b = [missing for i in range(0.0, 1000000.0)] # Creating an array of 1.000.000 missing values\n",
    "a = Float64.(a)\n",
    "c = vcat(a,b) #concat\n",
    "shuffle!(c) #shuffle\n",
    "df = DataFrame([c],:auto ) #Julia is vervose by default, so it's going to print last line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 78 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m34.833 ms\u001b[22m\u001b[39m … \u001b[35m150.999 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 49.13%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m48.612 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m64.130 ms\u001b[22m\u001b[39m ± \u001b[32m 32.468 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m18.52% ± 19.51%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m▆\u001b[39m \u001b[39m█\u001b[39m \u001b[39m▅\u001b[39m \u001b[34m▂\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▄\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▄\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[32m█\u001b[39m\u001b[39m▅\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m \u001b[39m▁\n",
       "  34.8 ms\u001b[90m         Histogram: frequency by time\u001b[39m          140 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m97.27 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m4\u001b[39m."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now with our nice dataframe, let's test replace, and replace!\n",
    "@benchmark d = replace(df[:,\"x1\"], missing => 0) #63.290 ms ±  35.548 ms after 79 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 111 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m28.658 ms\u001b[22m\u001b[39m … \u001b[35m112.027 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 61.42%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m39.111 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m45.079 ms\u001b[22m\u001b[39m ± \u001b[32m 17.816 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m11.49% ± 17.34%\n",
       "\n",
       "  \u001b[39m▄\u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[34m▃\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[32m▃\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▇\u001b[39m▁\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▅\u001b[39m▄\u001b[32m█\u001b[39m\u001b[39m▄\u001b[39m▁\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m \u001b[39m▃\n",
       "  28.7 ms\u001b[90m         Histogram: frequency by time\u001b[39m          108 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m51.50 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2\u001b[39m."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark replace!(df[:,\"x1\"], missing => 0)# 96 samples 45.079 ms ±  17.816 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... the ! is always faste than the non ! function. However, although almost every Julia func as an ! variant, non all of them actually works (or at least not now). I think that all base func has ! working and just some packages doesn't. So better try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sklearn on Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can use Sklearn models and pipelines, you probably don't want to. Why? Well, It's not an official implementation, or let's say that it's not even implemented in Julia. It's a wrapper of python Sklearn. So each time you executed code in Julia, you're running Python in the backend. So probably not worth it. In the MLJ library you have more optimized models and some preprocessing options. The same goes with Tensorflow.jl\n",
    "\n",
    "If you want to try it, I leave you with an example on how to translate the \"py_folder/pipeline.py\" to Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn.Pipelines: Pipeline, make_pipeline\n",
    "\n",
    "@sk_import preprocessing: (OneHotEncoder, StandardScaler)\n",
    "@sk_import impute: (SimpleImputer)\n",
    "\n",
    "PROCESS_PIPE = DataFrameMapper([\n",
    "        (Constants.COLUMNS_NUM,[SimpleImputer(strategy=\"median\"),\n",
    "                                StandardScaler()]),\n",
    "        (Constants.COLUMNS_STR,[SimpleImputer(strategy=\"most_frequent\"),\n",
    "                                OneHotEncoder(drop=\"first\",sparse=false)]),\n",
    "        (Constants.COLUMNS_BOOL,[SimpleImputer(strategy=\"most_frequent\")]), \n",
    "        ]; missing2NaN=true)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c8f8bb4cd98e4a4ff5b48076e04c9143f54f24f3daf823607748b43789fc942"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
